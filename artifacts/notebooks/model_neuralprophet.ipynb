{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daee8700",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Import NeuralProphet\n",
    "from neuralprophet import NeuralProphet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "emiten = 'DEWA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041df5a3",
   "metadata": {},
   "source": [
    "### Fungsi untuk Rekayasa Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Menciptakan fitur-fitur teknikal (sesuai dengan hybrid model)\"\"\"\n",
    "    data = df.copy()\n",
    "\n",
    "    # Previous Close\n",
    "    data['Prev Close'] = data['Close'].shift(1)\n",
    "    \n",
    "    # Moving Averages\n",
    "    data['MA20'] = data['Close'].rolling(window=20).mean()\n",
    "    data['MA50'] = data['Close'].rolling(window=50).mean()\n",
    "\n",
    "    # RSI\n",
    "    delta = data['Close'].diff(1)\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    gain_avg = gain.rolling(window=14).mean()\n",
    "    loss_avg = loss.rolling(window=14).mean()\n",
    "    rs = gain_avg / (loss_avg + 1e-8)\n",
    "    data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD\n",
    "    data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "    data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "    data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "    data['Signal Line'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Bollinger Bands\n",
    "    data['BB_Upper'] = data['Close'].rolling(window=20).mean() + 2*data['Close'].rolling(window=20).std()\n",
    "    data['BB_Lower'] = data['Close'].rolling(window=20).mean() - 2*data['Close'].rolling(window=20).std()\n",
    "\n",
    "    # ATR\n",
    "    high_low = data['High'] - data['Low']\n",
    "    high_close = abs(data['High'] - data['Close'].shift(1))\n",
    "    low_close = abs(data['Low'] - data['Close'].shift(1))\n",
    "    true_range = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    data['ATR'] = true_range.max(axis=1).rolling(window=14).mean()\n",
    "\n",
    "    # Stochastic\n",
    "    data['Stochastic_K'] = 100 * (data['Close'] - data['Low'].rolling(window=14).min()) / \\\n",
    "                           (data['High'].rolling(window=14).max() - data['Low'].rolling(window=14).min())\n",
    "    data['Stochastic_D'] = data['Stochastic_K'].rolling(window=3).mean()\n",
    "\n",
    "    # CCI\n",
    "    data['CCI'] = (data['Close'] - data['Close'].rolling(window=20).mean()) / \\\n",
    "                  (0.015 * data['Close'].rolling(window=20).std())\n",
    "\n",
    "    # OBV\n",
    "    data['OBV'] = np.where(data['Close'] > data['Close'].shift(1), data['Volume'],\n",
    "                           np.where(data['Close'] < data['Close'].shift(1), -data['Volume'], 0))\n",
    "    data['OBV'] = data['OBV'].cumsum()\n",
    "\n",
    "    # Lag features\n",
    "    for i in range(1, 6):\n",
    "        data[f'Lag{i}'] = data['Close'].shift(i)\n",
    "\n",
    "    data = data.dropna().reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eadf7a2",
   "metadata": {},
   "source": [
    "### LANGKAH 1: Download Data & Rekayasa Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì• Downloading stock data...\")\n",
    "# Kita ambil strukturnya agar aman\n",
    "data_raw = yf.download(emiten + '.JK', start='2020-01-01', end='2025-01-01', progress=False)\n",
    "\n",
    "# --- FIX STRUKTUR DATA YFINANCE ---\n",
    "# Jika MultiIndex (ada level Ticker), kita buang level Tickernya\n",
    "if isinstance(data_raw.columns, pd.MultiIndex):\n",
    "    data_raw.columns = data_raw.columns.get_level_values(0)\n",
    "\n",
    "# Pastikan index adalah Datetime\n",
    "if not isinstance(data_raw.index, pd.DatetimeIndex):\n",
    "    data_raw.index = pd.to_datetime(data_raw.index)\n",
    "\n",
    "print(\"‚úÖ Data downloaded & structure fixed\")\n",
    "print(f\"   Shape: {data_raw.shape}\")\n",
    "print(f\"   Columns: {data_raw.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd900d",
   "metadata": {},
   "source": [
    "### LANGKAH 2: Persiapan Data & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80157185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîß Creating technical indicators...\")\n",
    "data_featured = create_features(data_raw)\n",
    "\n",
    "# Setup Dataframe NeuralProphet - gunakan Close sebagai target (sama seperti Prophet)\n",
    "df_prophet = data_featured.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "\n",
    "# Fitur yang dipilih - sama dengan hybrid model\n",
    "selected_features = [\n",
    "    'Prev Close', 'MA20', 'MA50', 'MACD', 'Signal Line',\n",
    "    'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'RSI',\n",
    "    'BB_Upper', 'BB_Lower', 'ATR', 'Stochastic_K', 'Stochastic_D', 'CCI', 'OBV', 'Volume'\n",
    "]\n",
    "\n",
    "# Siapkan kolom final\n",
    "columns_for_model = ['ds', 'y'] + selected_features\n",
    "df_model_ready = df_prophet[columns_for_model]\n",
    "\n",
    "print(\"\\nüìä Splitting data...\")\n",
    "# Split data secara kronologis\n",
    "train_size = int(len(df_model_ready) * 0.8)\n",
    "\n",
    "# Gunakan .copy() untuk memutus referensi pandas (mencegah warning)\n",
    "train_df = df_model_ready.iloc[:train_size].copy()\n",
    "test_df = df_model_ready.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"‚úÖ Data split completed\")\n",
    "print(f\"   Training samples: {len(train_df)}\")\n",
    "print(f\"   Testing samples: {len(test_df)}\")\n",
    "print(f\"   Total features: {len(selected_features)}\")\n",
    "print(f\"   Target: Close (same as Prophet model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚öñÔ∏è  Normalizing technical features (same as Prophet)...\")\n",
    "\n",
    "# Gunakan .copy() untuk menghindari warning\n",
    "train_df_scaled = train_df.copy()\n",
    "test_df_scaled = test_df.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Hanya normalisasi kolom FITUR (regressors), JANGAN normalisasi 'y' (Target)\n",
    "# Fit pada training, transform pada training & testing (SAMA SEPERTI PROPHET)\n",
    "train_df_scaled[selected_features] = scaler.fit_transform(train_df[selected_features])\n",
    "test_df_scaled[selected_features] = scaler.transform(test_df[selected_features])\n",
    "\n",
    "# Update train_df dan test_df dengan versi yang sudah di-scale\n",
    "train_df = train_df_scaled\n",
    "test_df = test_df_scaled\n",
    "\n",
    "print(\"‚úÖ Features scaled to 0-1 range (same as Prophet)\")\n",
    "print(\"   Target 'y' (Close) kept in original scale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62925547",
   "metadata": {},
   "source": [
    "### LANGKAH 3: Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70380ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç Seed sweep disabled ‚Äî using fixed seed=42.\")\n",
    "DO_SEED_SWEEP = False\n",
    "BEST_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Seeding for reproducibility (fixed to 42)...\")\n",
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "BEST_SEED = 42  # fixed seed\n",
    "\n",
    "def set_seed(seed: int) -> int:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        if hasattr(torch, \"cuda\") and torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        if hasattr(torch.backends, \"cudnn\"):\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    return seed\n",
    "\n",
    "set_seed(BEST_SEED)\n",
    "print(f\"‚úÖ Seed set: {BEST_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÇ Training NeuralProphet model (config matched with Prophet)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Ensure seed is applied\n",
    "try:\n",
    "    BEST_SEED\n",
    "except NameError:\n",
    "    BEST_SEED = 42\n",
    "set_seed(BEST_SEED)\n",
    "\n",
    "# Build model - CONFIG DISESUAIKAN DENGAN PROPHET untuk apple-to-apple comparison\n",
    "try:\n",
    "    model = NeuralProphet(\n",
    "        n_forecasts=1,\n",
    "        n_changepoints=25,        # SAMA dengan Prophet\n",
    "        learning_rate=0.01,       \n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        loss_func=\"Huber\",\n",
    "        normalize=\"minmax\",       # NeuralProphet normalize target juga (berbeda dengan Prophet approach)\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=True,\n",
    "        random_seed=42,\n",
    "        drop_missing=True,\n",
    "    )\n",
    "except TypeError:\n",
    "    model = NeuralProphet(\n",
    "        n_forecasts=1,\n",
    "        n_changepoints=25,\n",
    "        learning_rate=0.01,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        loss_func=\"Huber\",\n",
    "        normalize=\"minmax\",\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=True,\n",
    "        drop_missing=True,\n",
    "    )\n",
    "\n",
    "# Tambahkan semua fitur sebagai future regressors (loop per fitur)\n",
    "for feat in selected_features:\n",
    "    model = model.add_future_regressor(feat)\n",
    "\n",
    "metrics = model.fit(train_df, freq=\"D\", progress=\"bar\")\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Training selesai dalam {training_time:.2f} detik | Seed={BEST_SEED}\")\n",
    "print(f\"   Config: Closest match to Prophet\")\n",
    "print(f\"   - n_changepoints=25 (same as Prophet)\")\n",
    "print(f\"   - normalize='minmax' (NeuralProphet handles target internally)\")\n",
    "print(f\"   - Features manually scaled with MinMaxScaler (same as Prophet)\")\n",
    "print(f\"   - seasonality: weekly+yearly (same as Prophet)\")\n",
    "print(metrics.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738b6f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93ff3196",
   "metadata": {},
   "source": [
    "### LANGKAH 4: Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÆ Making predictions...\")\n",
    "\n",
    "# Prediksi pada test data\n",
    "forecast_test = model.predict(test_df)\n",
    "\n",
    "# Ambil prediksi Close price langsung dari yhat1 (sama seperti Prophet)\n",
    "reconstructed_prices = forecast_test['yhat1'].values\n",
    "\n",
    "# Harga aktual dari data asli\n",
    "original_train_size = len(train_df) + (len(data_featured) - len(df_model_ready))\n",
    "y_test_actual = data_featured['Close'].iloc[original_train_size:].values\n",
    "\n",
    "# Pastikan ukuran sama\n",
    "min_len = min(len(reconstructed_prices), len(y_test_actual))\n",
    "reconstructed_prices = reconstructed_prices[:min_len]\n",
    "y_test_actual = y_test_actual[:min_len]\n",
    "\n",
    "# Hapus NaN values (jika ada)\n",
    "valid_mask = ~np.isnan(reconstructed_prices) & ~np.isnan(y_test_actual)\n",
    "reconstructed_prices = reconstructed_prices[valid_mask]\n",
    "y_test_actual = y_test_actual[valid_mask]\n",
    "\n",
    "# Simpan hasil raw untuk perbandingan\n",
    "reconstructed_prices_raw = reconstructed_prices.copy()\n",
    "\n",
    "print(f\"‚úÖ Predictions completed\")\n",
    "print(f\"   Predicting Close prices directly (same as Prophet)\")\n",
    "print(f\"   Valid test samples: {len(reconstructed_prices)}\")\n",
    "print(f\"   Actual samples: {len(y_test_actual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed768c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: cek prediksi\n",
    "print(\"\\nüîç Debug predictions...\")\n",
    "print(f\"forecast_test shape: {forecast_test.shape}\")\n",
    "print(f\"forecast_test columns: {forecast_test.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 yhat1 values:\")\n",
    "print(forecast_test['yhat1'].head())\n",
    "print(f\"\\nNumber of NaN in yhat1: {forecast_test['yhat1'].isna().sum()}\")\n",
    "print(f\"Total predictions: {len(forecast_test['yhat1'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Evaluating RAW prediction (before post-processing)...\")\n",
    "\n",
    "# Evaluasi hasil raw\n",
    "mae_raw = mean_absolute_error(y_test_actual, reconstructed_prices_raw)\n",
    "mse_raw = mean_squared_error(y_test_actual, reconstructed_prices_raw)\n",
    "rmse_raw = math.sqrt(mse_raw)\n",
    "r2_raw = r2_score(y_test_actual, reconstructed_prices_raw)\n",
    "mape_raw = np.mean(np.abs((y_test_actual - reconstructed_prices_raw) / y_test_actual)) * 100\n",
    "\n",
    "# Directional Accuracy (DA) untuk raw\n",
    "T_raw = len(y_test_actual) - 1\n",
    "actual_diff_raw = np.diff(y_test_actual)\n",
    "pred_diff_raw = np.diff(reconstructed_prices_raw)\n",
    "ai_raw = (np.sign(actual_diff_raw) == np.sign(pred_diff_raw)).astype(int)\n",
    "da_raw = (1/T_raw) * np.sum(ai_raw) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RAW NEURALPROPHET PREDICTION (No Post-Processing)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"RMSE  : {rmse_raw:.4f}\")\n",
    "print(f\"MAE   : {mae_raw:.4f}\")\n",
    "print(f\"R¬≤    : {r2_raw:.4f}\")\n",
    "print(f\"MAPE  : {mape_raw:.2f}%\")\n",
    "print(f\"DA    : {da_raw:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768dd42",
   "metadata": {},
   "source": [
    "### LANGKAH 5: Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a92c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà Evaluating model performance (Actual Price)...\")\n",
    "mae = mean_absolute_error(y_test_actual, reconstructed_prices)\n",
    "mse = mean_squared_error(y_test_actual, reconstructed_prices)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(y_test_actual, reconstructed_prices)\n",
    "mape = np.mean(np.abs((y_test_actual - reconstructed_prices) / y_test_actual)) * 100\n",
    "\n",
    "# --- PERHITUNGAN DA SESUAI RUMUS DI GAMBAR ---\n",
    "# T adalah jumlah total interval perubahan (n-1)\n",
    "T = len(y_test_actual) - 1\n",
    "\n",
    "# 1. Hitung perubahan arah aktual dan prediksi (diff)\n",
    "actual_diff = np.diff(y_test_actual)\n",
    "pred_diff = np.diff(reconstructed_prices)\n",
    "\n",
    "# 2. Definisikan ai (Indikator: 1 jika arah sama, 0 jika berbeda)\n",
    "# Sesuai rumus: ai = 1 jika sign(perubahan) sama\n",
    "ai = (np.sign(actual_diff) == np.sign(pred_diff)).astype(int)\n",
    "\n",
    "# 3. Hitung DA = (1/T) * Sum(ai) * 100%\n",
    "da = (1/T) * np.sum(ai) * 100\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä NEURALPROPHET MODEL - EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"RMSE  : {rmse:.4f}\")\n",
    "print(f\"MAE   : {mae:.4f}\")\n",
    "print(f\"R¬≤    : {r2:.4f}\")\n",
    "print(f\"MAPE  : {mape:.2f}%\")\n",
    "print(f\"DA    : {da:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b394a",
   "metadata": {},
   "source": [
    "### LANGKAH 6: Visualisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Creating visualizations...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Time Series\n",
    "ax1 = axes[0, 0]\n",
    "train_dates = data_featured['Date'].iloc[:original_train_size]\n",
    "train_prices = data_featured['Close'].iloc[:original_train_size]\n",
    "test_dates = data_featured['Date'].iloc[original_train_size:]\n",
    "\n",
    "ax1.plot(train_dates, train_prices, label='Training Data', color='blue', alpha=0.5)\n",
    "ax1.plot(test_dates, y_test_actual, label='Actual Price', color='green', linewidth=2)\n",
    "ax1.plot(test_dates, reconstructed_prices, label='Predicted Price',\n",
    "         color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_title(\"NeuralProphet: Price Prediction vs Actual\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Stock Price (IDR)\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Scatter\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_test_actual, reconstructed_prices, alpha=0.6, color='purple')\n",
    "ax2.plot([y_test_actual.min(), y_test_actual.max()],\n",
    "         [y_test_actual.min(), y_test_actual.max()], 'r--', lw=2)\n",
    "ax2.set_xlabel('Actual Price')\n",
    "ax2.set_ylabel('Predicted Price')\n",
    "ax2.set_title(f'Correlation (R¬≤ = {r2:.4f})', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Residuals\n",
    "ax3 = axes[1, 0]\n",
    "residuals = y_test_actual - reconstructed_prices\n",
    "ax3.plot(residuals, color='orange', alpha=0.7)\n",
    "ax3.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax3.set_title('Residuals Plot', fontsize=14)\n",
    "ax3.set_xlabel('Sample Index')\n",
    "ax3.set_ylabel('Residuals')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Error Distribution\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(residuals, bins=30, alpha=0.7, color='teal', edgecolor='black')\n",
    "ax4.set_title('Error Distribution', fontsize=14)\n",
    "ax4.set_xlabel('Prediction Error')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('üìà NeuralProphet Model - Comprehensive Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('neuralprophet_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Visualization saved as 'neuralprophet_results.png'\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ NeuralProphet Model Analysis Completed!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07012fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export NeuralProphet artifact to repository 'models' with scaler + features\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "# Prefer the trained variables from above\n",
    "neural_model = globals().get('model', None)\n",
    "scaler_obj = globals().get('scaler', None)\n",
    "feature_cols = globals().get('selected_features', None)\n",
    "\n",
    "if scaler_obj is None:\n",
    "    raise RuntimeError('No fitted MinMaxScaler found (variable `scaler`). Run training cells first.')\n",
    "if neural_model is None or not isinstance(neural_model, NeuralProphet):\n",
    "    raise RuntimeError('No NeuralProphet model instance found (variable `model`). Run training cells first.')\n",
    "if feature_cols is None or len(feature_cols) == 0:\n",
    "    # Fallback: infer from a df that contains ds/y and indicators\n",
    "    candidate_dfs = [v for v in globals().values() if isinstance(v, pd.DataFrame)]\n",
    "    known = {\n",
    "        'Prev Close','MA20','MA50','MACD','Signal Line','Lag1','Lag2','Lag3','Lag4','Lag5','RSI',\n",
    "        'BB_Upper','BB_Lower','ATR','Stochastic_K','Stochastic_D','CCI','OBV','High','Low','Volume'\n",
    "    }\n",
    "    for d in candidate_dfs:\n",
    "        cols = list(d.columns)\n",
    "        if 'ds' in cols and ('y' in cols or 'Close' in cols):\n",
    "            feats = [c for c in cols if c not in ['ds','y','Close']]\n",
    "            if len(set(feats) & known) >= 5:\n",
    "                feature_cols = feats\n",
    "                break\n",
    "if feature_cols is None or len(feature_cols) == 0:\n",
    "    raise RuntimeError('Could not determine feature_columns; ensure `selected_features` is defined.')\n",
    "\n",
    "# Helper: find repo root\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / 'requirements.txt').exists() or (p / 'app.py').exists() or (p / '.git').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "repo_root = find_repo_root(Path.cwd())\n",
    "export_dir = (repo_root / 'models')\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect metrics from earlier cells if available\n",
    "metrics_map = {\n",
    "    'rmse': float(globals().get('rmse')) if 'rmse' in globals() and globals().get('rmse') is not None else None,\n",
    "    'mae': float(globals().get('mae')) if 'mae' in globals() and globals().get('mae') is not None else None,\n",
    "    'mape': float(globals().get('mape')) if 'mape' in globals() and globals().get('mape') is not None else None,\n",
    "    'r2': float(globals().get('r2')) if 'r2' in globals() and globals().get('r2') is not None else None,\n",
    "    'directional_accuracy': float(globals().get('da')) if 'da' in globals() and globals().get('da') is not None else None,\n",
    "}\n",
    "\n",
    "artifact = {\n",
    "    'model_type': 'neuralprophet',\n",
    "    'neuralprophet': neural_model,\n",
    "    'scaler': scaler_obj,\n",
    "    'feature_columns': feature_cols,\n",
    "    'metrics': metrics_map,\n",
    "}\n",
    "\n",
    "artifact_path = export_dir / (emiten + '_neuralprophet_meta.joblib')\n",
    "\n",
    "# Try joblib dump first; if it fails (pickling issues), fall back to NeuralProphet.save()\n",
    "try:\n",
    "    joblib.dump(artifact, str(artifact_path))\n",
    "    print('‚úÖ Saved artifact:', artifact_path.resolve())\n",
    "except Exception as e:\n",
    "    print('‚ö†Ô∏è joblib dump failed; saving via NeuralProphet.save()', e)\n",
    "    model_dir = export_dir / (emiten + '_neuralprophet_meta.joblib')\n",
    "    try:\n",
    "        neural_model.save(str(model_dir))\n",
    "        meta = {\n",
    "            'model_type': 'neuralprophet',\n",
    "            'model_dir': str(model_dir),\n",
    "            'scaler': scaler_obj,\n",
    "            'feature_columns': feature_cols,\n",
    "            'metrics': metrics_map,\n",
    "        }\n",
    "        meta_path = export_dir / (emiten + '_neuralprophet_meta.joblib')\n",
    "        joblib.dump(meta, str(meta_path))\n",
    "        print('‚úÖ Saved model at:', model_dir.resolve())\n",
    "        print('‚úÖ Saved meta artifact:', meta_path.resolve())\n",
    "    except Exception as e2:\n",
    "        raise RuntimeError(f'Failed to save NeuralProphet model: {e2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
