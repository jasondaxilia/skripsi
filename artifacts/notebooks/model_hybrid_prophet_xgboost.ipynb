{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8050a29",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5941ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "emiten = 'DEWA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63aa7f",
   "metadata": {},
   "source": [
    "### LANGKAH 1: Download Data & Rekayasa Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117298e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“¥ Downloading stock data...\")\n",
    "data_raw = yf.download(emiten+'.JK', start='2020-01-01', end='2025-01-01', progress=False)\n",
    "data = data_raw.copy()\n",
    "\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = [col[0] for col in data.columns]\n",
    "\n",
    "print(\"âœ… Data downloaded successfully\")\n",
    "print(f\"   Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf65ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahkan Fitur Teknikal\n",
    "print(\"\\nðŸ”§ Creating technical indicators...\")\n",
    "data['Prev Close'] = data['Close'].shift(1)\n",
    "data['MA20'] = data['Close'].rolling(window=20).mean()\n",
    "data['MA50'] = data['Close'].rolling(window=50).mean()\n",
    "\n",
    "# RSI\n",
    "delta = data['Close'].diff(1)\n",
    "gain = delta.where(delta > 0, 0)\n",
    "loss = -delta.where(delta < 0, 0)\n",
    "gain_avg = gain.rolling(window=14).mean()\n",
    "loss_avg = loss.rolling(window=14).mean()\n",
    "rs = gain_avg / (loss_avg + 1e-8)\n",
    "data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# MACD\n",
    "data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = data['EMA12'] - data['EMA26']\n",
    "data['Signal Line'] = data['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# Bollinger Bands\n",
    "data['BB_Upper'] = data['Close'].rolling(window=20).mean() + 2*data['Close'].rolling(window=20).std()\n",
    "data['BB_Lower'] = data['Close'].rolling(window=20).mean() - 2*data['Close'].rolling(window=20).std()\n",
    "\n",
    "# ATR\n",
    "high_low = data['High'] - data['Low']\n",
    "high_close = abs(data['High'] - data['Close'].shift(1))\n",
    "low_close = abs(data['Low'] - data['Close'].shift(1))\n",
    "true_range = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "data['ATR'] = true_range.max(axis=1).rolling(window=14).mean()\n",
    "\n",
    "# Stochastic\n",
    "data['Stochastic_K'] = 100 * (data['Close'] - data['Low'].rolling(window=14).min()) / \\\n",
    "                       (data['High'].rolling(window=14).max() - data['Low'].rolling(window=14).min())\n",
    "data['Stochastic_D'] = data['Stochastic_K'].rolling(window=3).mean()\n",
    "\n",
    "# CCI\n",
    "data['CCI'] = (data['Close'] - data['Close'].rolling(window=20).mean()) / \\\n",
    "              (0.015 * data['Close'].rolling(window=20).std())\n",
    "\n",
    "# OBV\n",
    "data['OBV'] = np.where(data['Close'] > data['Close'].shift(1), data['Volume'],\n",
    "                       np.where(data['Close'] < data['Close'].shift(1), -data['Volume'], 0))\n",
    "data['OBV'] = data['OBV'].cumsum()\n",
    "\n",
    "# Lag features\n",
    "for i in range(1, 6):\n",
    "    data[f'Lag{i}'] = data['Close'].shift(i)\n",
    "\n",
    "data = data.dropna()\n",
    "data = data.reset_index()\n",
    "\n",
    "print(f\"âœ… Technical indicators created\")\n",
    "print(f\"   Final shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4db844",
   "metadata": {},
   "source": [
    "### LANGKAH 2: Persiapan Data untuk Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Preparing data for Prophet...\")\n",
    "df_prophet = data.rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "\n",
    "regressors = [\n",
    "    'Prev Close', 'MA20', 'MA50', 'MACD', 'Signal Line',\n",
    "    'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'RSI',\n",
    "    'BB_Upper', 'BB_Lower', 'ATR', 'Stochastic_K', 'Stochastic_D', 'CCI', 'OBV', 'Volume'\n",
    "]\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(df_prophet) * 0.8)\n",
    "train_df = df_prophet[:train_size]\n",
    "test_df = df_prophet[train_size:]\n",
    "\n",
    "print(f\"âœ… Data split completed\")\n",
    "print(f\"   Training samples: {len(train_df)}\")\n",
    "print(f\"   Testing samples: {len(test_df)}\")\n",
    "print(f\"   Number of features: {len(regressors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df44a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš–ï¸  Normalizing technical features...\")\n",
    "\n",
    "# Kita gunakan .copy() agar tidak muncul SettingWithCopyWarning\n",
    "train_df = df_prophet[:train_size].copy()\n",
    "test_df = df_prophet[train_size:].copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Hanya normalisasi kolom FITUR (regressors), JANGAN normalisasi 'y' (Target)\n",
    "# Fit pada training, transform pada training & testing\n",
    "train_df[regressors] = scaler.fit_transform(train_df[regressors])\n",
    "test_df[regressors] = scaler.transform(test_df[regressors])\n",
    "\n",
    "print(\"âœ… Features scaled to 0-1 range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c412dc",
   "metadata": {},
   "source": [
    "### LANGKAH 3: Membuat & Melatih Model Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ¤– Training Prophet model...\")\n",
    "model_prophet = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    changepoint_prior_scale=0.05,\n",
    "    seasonality_prior_scale=10.0,\n",
    "    holidays_prior_scale=10.0,\n",
    "    n_changepoints=25\n",
    ")\n",
    "\n",
    "for regressor in regressors:\n",
    "    model_prophet.add_regressor(regressor, prior_scale=10.0)\n",
    "\n",
    "model_prophet.fit(train_df)\n",
    "print(\"âœ… Prophet model trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee905e",
   "metadata": {},
   "source": [
    "### LANGKAH 4: Persiapan Data untuk XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1979d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”§ Preparing data for XGBoost...\")\n",
    "\n",
    "feature_cols = regressors.copy()\n",
    "available_features = [col for col in feature_cols if col in train_df.columns]\n",
    "\n",
    "if len(available_features) < len(feature_cols):\n",
    "    missing = set(feature_cols) - set(available_features)\n",
    "    print(f\"âš ï¸ Warning: Some features not found: {missing}\")\n",
    "    feature_cols = available_features\n",
    "\n",
    "print(f\"âœ… Using {len(feature_cols)} features for XGBoost\")\n",
    "\n",
    "# Extract features dan target\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df['y'].values\n",
    "\n",
    "X_test = test_df[feature_cols].values\n",
    "y_test = test_df['y'].values\n",
    "\n",
    "# Handle missing values\n",
    "if np.any(np.isnan(X_train)) or np.any(np.isnan(X_test)):\n",
    "    print(\"âš ï¸ Found NaN values, filling with median...\")\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "\n",
    "print(f\"   X_train shape: {X_train.shape}\")\n",
    "print(f\"   X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072f04a",
   "metadata": {},
   "source": [
    "### LANGKAH 5: Dapatkan Prediksi Prophet & Hitung Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”® Getting Prophet predictions...\")\n",
    "\n",
    "# Prediksi Prophet pada data training\n",
    "forecast_train = model_prophet.predict(train_df)\n",
    "prophet_pred_train = forecast_train['yhat'].values\n",
    "\n",
    "# Prediksi Prophet pada data test\n",
    "future = test_df.drop(columns='y')\n",
    "forecast = model_prophet.predict(future)\n",
    "prophet_pred_test = forecast['yhat'].values\n",
    "\n",
    "print(f\"âœ… Prophet predictions obtained\")\n",
    "print(f\"   Train predictions: {len(prophet_pred_train)}\")\n",
    "print(f\"   Test predictions: {len(prophet_pred_test)}\")\n",
    "\n",
    "# Hitung Residual (error Prophet)\n",
    "print(\"\\nðŸ“Š Calculating Prophet residuals...\")\n",
    "train_residuals = y_train - prophet_pred_train\n",
    "\n",
    "print(f\"âœ… Residuals calculated\")\n",
    "print(f\"   Mean residual: {np.mean(train_residuals):.4f}\")\n",
    "print(f\"   Std residual: {np.std(train_residuals):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d0c21",
   "metadata": {},
   "source": [
    "### LANGKAH 6: Latih XGBoost untuk Memprediksi Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ¤– Training XGBoost to learn Prophet's errors...\")\n",
    "print(\"   This may take a few minutes...\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=50,         # Turunkan drastis (cegah overfitting noise)\n",
    "    learning_rate=0.01,      # Sangat lambat\n",
    "    max_depth=2,             # Sangat dangkal (hanya pola besar)\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.5,\n",
    "    min_child_weight=20,     # SANGAT TINGGI (Abaikan fluktuasi kecil)\n",
    "    gamma=1.0,               # SANGAT TINGGI (Pruning agresif)\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=50.0,         # Regularisasi KUAT (supaya model 'cari aman')\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train,\n",
    "    train_residuals,\n",
    "    eval_set=[(X_train, train_residuals)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"âœ… XGBoost training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5dbebb",
   "metadata": {},
   "source": [
    "### LANGKAH 7: Buat Prediksi Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b741aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¯ Making hybrid predictions...\")\n",
    "\n",
    "# Prediksi residual dengan XGBoost\n",
    "xgb_pred_residuals = xgb_model.predict(X_test)\n",
    "\n",
    "# Gabungkan: Hybrid = Prophet + XGBoost Correction\n",
    "hybrid_prediction = prophet_pred_test + xgb_pred_residuals\n",
    "\n",
    "print(\"âœ… Hybrid predictions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f164da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hybrid_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34d836",
   "metadata": {},
   "source": [
    "### LANGKAH 8: Evaluasi dan Perbandingan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ˆ Evaluating model performance...\")\n",
    "\n",
    "# Metrik Prophet Only\n",
    "mae_prophet = mean_absolute_error(y_test, prophet_pred_test)\n",
    "rmse_prophet = np.sqrt(mean_squared_error(y_test, prophet_pred_test))\n",
    "r2_prophet = r2_score(y_test, prophet_pred_test)\n",
    "mape_prophet = np.mean(np.abs((y_test - prophet_pred_test) / y_test)) * 100\n",
    "\n",
    "# Metrik Hybrid Model\n",
    "mae_hybrid = mean_absolute_error(y_test, hybrid_prediction)\n",
    "rmse_hybrid = np.sqrt(mean_squared_error(y_test, hybrid_prediction))\n",
    "r2_hybrid = r2_score(y_test, hybrid_prediction)\n",
    "mape_hybrid = np.mean(np.abs((y_test - hybrid_prediction) / y_test)) * 100\n",
    "\n",
    "# --- PERHITUNGAN DA SESUAI RUMUS DI GAMBAR ---\n",
    "# T adalah jumlah total interval perubahan (n-1)\n",
    "T = len(y_test) - 1\n",
    "\n",
    "# 1. Hitung perubahan arah aktual dan prediksi\n",
    "actual_diff = np.diff(y_test)\n",
    "prophet_diff = np.diff(prophet_pred_test)\n",
    "hybrid_diff = np.diff(hybrid_prediction)\n",
    "\n",
    "# 2. Definisikan ai (Indikator: 1 jika arah sama, 0 jika berbeda)\n",
    "# Sesuai rumus: ai = 1 jika sign perubahan sama\n",
    "ai_prophet = (np.sign(actual_diff) == np.sign(prophet_diff)).astype(int)\n",
    "ai_hybrid = (np.sign(actual_diff) == np.sign(hybrid_diff)).astype(int)\n",
    "\n",
    "# 3. Hitung DA = (1/T) * Sum(ai) * 100%\n",
    "da_prophet = (1/T) * np.sum(ai_prophet) * 100\n",
    "da_hybrid = (1/T) * np.sum(ai_hybrid) * 100\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Hitung improvement\n",
    "rmse_improvement = ((rmse_prophet - rmse_hybrid) / rmse_prophet) * 100\n",
    "mae_improvement = ((mae_prophet - mae_hybrid) / mae_prophet) * 100\n",
    "r2_improvement = ((r2_hybrid - r2_prophet) / abs(r2_prophet)) * 100\n",
    "da_improvement = da_hybrid - da_prophet\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š HYBRID MODEL - EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ”µ PROPHET ONLY:\")\n",
    "print(f\"   RMSE  : {rmse_prophet:.4f}\")\n",
    "print(f\"   MAE   : {mae_prophet:.4f}\")\n",
    "print(f\"   RÂ²    : {r2_prophet:.4f}\")\n",
    "print(f\"   MAPE  : {mape_prophet:.2f}%\")\n",
    "print(f\"   DA    : {da_prophet:.2f}%\")\n",
    "\n",
    "print(\"\\nðŸŸ¢ HYBRID (PROPHET + XGBOOST):\")\n",
    "print(f\"   RMSE  : {rmse_hybrid:.4f}\")\n",
    "print(f\"   MAE   : {mae_hybrid:.4f}\")\n",
    "print(f\"   RÂ²    : {r2_hybrid:.4f}\")\n",
    "print(f\"   MAPE  : {mape_hybrid:.2f}%\")\n",
    "print(f\"   DA    : {da_hybrid:.2f}%\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ IMPROVEMENT:\")\n",
    "print(f\"   RMSE  : {rmse_improvement:+.2f}%\")\n",
    "print(f\"   MAE   : {mae_improvement:+.2f}%\")\n",
    "print(f\"   RÂ²    : {r2_improvement:+.2f}%\")\n",
    "print(f\"   DA    : {da_improvement:+.2f}%\")\n",
    "\n",
    "if rmse_improvement > 0:\n",
    "    print(f\"\\nâœ¨ Hybrid model is {rmse_improvement:.2f}% better than Prophet!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Prophet alone performs better by {abs(rmse_improvement):.2f}%\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14042f8e",
   "metadata": {},
   "source": [
    "### LANGKAH 9: Visualisasi Komprehensif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Creating visualizations...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# Plot 1: Time Series Comparison\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(test_df['ds'], y_test, label='Actual Price', color='black', linewidth=2.5, alpha=0.8)\n",
    "ax1.plot(test_df['ds'], prophet_pred_test, label='Prophet Only', color='blue',\n",
    "         linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax1.plot(test_df['ds'], hybrid_prediction, label='Hybrid (Prophet + XGBoost)',\n",
    "         color='red', linewidth=2, alpha=0.8)\n",
    "ax1.set_title('ðŸ“ˆ Comparison: Actual vs Prophet vs Hybrid', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date', fontsize=11)\n",
    "ax1.set_ylabel('Price (IDR)', fontsize=11)\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Prophet Scatter\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.scatter(y_test, prophet_pred_test, alpha=0.6, color='blue', s=30)\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax2.set_xlabel('Actual Price', fontsize=10)\n",
    "ax2.set_ylabel('Prophet Prediction', fontsize=10)\n",
    "ax2.set_title(f'Prophet: RÂ² = {r2_prophet:.4f}', fontsize=11)\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Hybrid Scatter\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.scatter(y_test, hybrid_prediction, alpha=0.6, color='red', s=30)\n",
    "ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax3.set_xlabel('Actual Price', fontsize=10)\n",
    "ax3.set_ylabel('Hybrid Prediction', fontsize=10)\n",
    "ax3.set_title(f'Hybrid: RÂ² = {r2_hybrid:.4f}', fontsize=11)\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Directional Accuracy Comparison\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "models = ['Prophet', 'Hybrid']\n",
    "da_values = [da_prophet, da_hybrid]\n",
    "colors_da = ['#3498db', '#e74c3c']\n",
    "bars = ax4.bar(models, da_values, color=colors_da, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax4.set_ylabel('Directional Accuracy (%)', fontsize=10)\n",
    "ax4.set_title('ðŸ“Š Directional Accuracy Comparison', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylim([0, 100])\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "for bar, value in zip(bars, da_values):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{value:.2f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 5: Residuals Comparison\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "prophet_residuals = y_test - prophet_pred_test\n",
    "hybrid_residuals = y_test - hybrid_prediction\n",
    "ax5.hist(prophet_residuals, bins=30, alpha=0.5, color='blue', label='Prophet', edgecolor='black')\n",
    "ax5.hist(hybrid_residuals, bins=30, alpha=0.5, color='red', label='Hybrid', edgecolor='black')\n",
    "ax5.axvline(x=0, color='black', linestyle='--', linewidth=2)\n",
    "ax5.set_xlabel('Prediction Error', fontsize=10)\n",
    "ax5.set_ylabel('Frequency', fontsize=10)\n",
    "ax5.set_title('Error Distribution Comparison', fontsize=11)\n",
    "ax5.legend(fontsize=9)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Metrics Comparison\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "metrics = ['RMSE', 'MAE', 'MAPE']\n",
    "prophet_metrics = [rmse_prophet, mae_prophet, mape_prophet]\n",
    "hybrid_metrics = [rmse_hybrid, mae_hybrid, mape_hybrid]\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "ax6.bar(x - width/2, prophet_metrics, width, label='Prophet', color='blue', alpha=0.7)\n",
    "ax6.bar(x + width/2, hybrid_metrics, width, label='Hybrid', color='red', alpha=0.7)\n",
    "ax6.set_ylabel('Error Value', fontsize=10)\n",
    "ax6.set_title('Error Metrics Comparison', fontsize=11, fontweight='bold')\n",
    "ax6.set_xticks(x)\n",
    "ax6.set_xticklabels(metrics)\n",
    "ax6.legend(fontsize=9)\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 7: RÂ² Comparison\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "r2_values = [r2_prophet, r2_hybrid]\n",
    "bars_r2 = ax7.bar(models, r2_values, color=colors_da, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax7.set_ylabel('RÂ² Score', fontsize=10)\n",
    "ax7.set_title('RÂ² Score Comparison', fontsize=11, fontweight='bold')\n",
    "ax7.set_ylim([min(r2_values) - 0.1, max(r2_values) + 0.1])\n",
    "ax7.grid(True, alpha=0.3, axis='y')\n",
    "for bar, value in zip(bars_r2, r2_values):\n",
    "    height = bar.get_height()\n",
    "    ax7.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot 8: Feature Importance (Top 15)\n",
    "ax8 = fig.add_subplot(gs[3, :])\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "bars = ax8.barh(range(len(importance_df)), importance_df['Importance'], color='steelblue')\n",
    "ax8.set_yticks(range(len(importance_df)))\n",
    "ax8.set_yticklabels(importance_df['Feature'])\n",
    "ax8.set_xlabel('Importance Score', fontsize=11)\n",
    "ax8.set_title('ðŸ” Top 15 Features for Error Correction (XGBoost)', fontsize=12, fontweight='bold')\n",
    "ax8.invert_yaxis()\n",
    "ax8.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for i, (bar, value) in enumerate(zip(bars, importance_df['Importance'])):\n",
    "    ax8.text(value, i, f' {value:.3f}', va='center', fontsize=8)\n",
    "\n",
    "plt.suptitle('ðŸš€ Prophet + XGBoost Hybrid Model - Comprehensive Analysis',\n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hybrid_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ… Visualization saved as 'hybrid_results.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5847bc2",
   "metadata": {},
   "source": [
    "### LANGKAH 10: Detailed Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02204911",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "print(f\"   - Prophet MAPE: {mape_prophet:.2f}%\")\n",
    "print(f\"   - Hybrid MAPE: {mape_hybrid:.2f}%\")\n",
    "print(f\"   - Accuracy Improvement: {mape_prophet - mape_hybrid:.2f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“Š DIRECTIONAL ACCURACY (DA) - Most Important for Trading:\")\n",
    "print(f\"   - Prophet DA: {da_prophet:.2f}%\")\n",
    "print(f\"   - Hybrid DA: {da_hybrid:.2f}%\")\n",
    "print(f\"   - DA Improvement: {da_improvement:+.2f}%\")\n",
    "\n",
    "if da_improvement > 0:\n",
    "    print(f\"   âœ… Hybrid model correctly predicts direction {da_improvement:.2f}% better!\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ Prophet predicts direction {abs(da_improvement):.2f}% better\")\n",
    "\n",
    "prophet_errors = np.abs(y_test - prophet_pred_test)\n",
    "hybrid_errors = np.abs(y_test - hybrid_prediction)\n",
    "print(f\"\\n   - Prophet Average Error: {np.mean(prophet_errors):.2f} IDR\")\n",
    "print(f\"   - Hybrid Average Error: {np.mean(hybrid_errors):.2f} IDR\")\n",
    "\n",
    "print(f\"\\n   - Top 3 Most Important Features for Error Correction:\")\n",
    "for i, row in importance_df.head(3).iterrows():\n",
    "    print(f\"     {i+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Prophet + XGBoost Hybrid Model Analysis Completed!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export trained models as Streamlit-ready artifacts ===\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# Ensure output directory exists\n",
    "out_dir = Path('../../models').resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect metrics if available\n",
    "metrics_prophet = {\n",
    "    'rmse': float(rmse_prophet) if 'rmse_prophet' in globals() else None,\n",
    "    'mae': float(mae_prophet) if 'mae_prophet' in globals() else None,\n",
    "    'mape': float(mape_prophet) if 'mape_prophet' in globals() else None,\n",
    "    'r2': float(r2_prophet) if 'r2_prophet' in globals() else None,\n",
    "    'directional_accuracy': float(da_prophet) if 'da_prophet' in globals() else None,\n",
    "}\n",
    "metrics_hybrid = {\n",
    "    'rmse': float(rmse_hybrid) if 'rmse_hybrid' in globals() else None,\n",
    "    'mae': float(mae_hybrid) if 'mae_hybrid' in globals() else None,\n",
    "    'mape': float(mape_hybrid) if 'mape_hybrid' in globals() else None,\n",
    "    'r2': float(r2_hybrid) if 'r2_hybrid' in globals() else None,\n",
    "    'directional_accuracy': float(da_hybrid) if 'da_hybrid' in globals() else None,\n",
    "}\n",
    "\n",
    "# Prophet-only artifact\n",
    "prophet_artifact = {\n",
    "    'model_type': 'prophet',\n",
    "    'model': model_prophet,\n",
    "    'feature_columns': feature_cols if 'feature_cols' in globals() else None,\n",
    "    'metrics': metrics_prophet,\n",
    "}\n",
    "prophet_path = out_dir / 'prophet.joblib'\n",
    "# joblib.dump(prophet_artifact, str(prophet_path))\n",
    "\n",
    "# Hybrid artifact (Prophet + XGBoost residual correction)\n",
    "# NOTE: Streamlit inference will carry-forward latest feature values for future periods.\n",
    "hybrid_artifact = {\n",
    "    'model_type': 'hybrid',\n",
    "    'prophet': model_prophet,\n",
    "    'xgb': xgb_model,\n",
    "    'feature_columns': feature_cols if 'feature_cols' in globals() else [],\n",
    "    'metrics': metrics_hybrid,\n",
    "}\n",
    "hybrid_path = out_dir / (emiten + '_hybrid.joblib')\n",
    "joblib.dump(hybrid_artifact, str(hybrid_path))\n",
    "\n",
    "print(f\"\\nâœ… Saved artifacts:\\n - {prophet_path}\\n - {hybrid_path}\")\n",
    "\n",
    "# Optional (recommended) Prophet JSON serialization for cross-version portability:\n",
    "# from prophet.serialize import model_to_json\n",
    "# with open(out_dir / 'prophet.json', 'w') as f:\n",
    "#     f.write(model_to_json(model_prophet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78420fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Re-export artifacts including the fitted scaler ===\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "out_dir = Path('../../models').resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# prophet_artifact = {\n",
    "#     'model_type': 'prophet',\n",
    "#     'model': model_prophet,\n",
    "#     'feature_columns': feature_cols if 'feature_cols' in globals() else None,\n",
    "#     'scaler': scaler if 'scaler' in globals() else None,\n",
    "#     'metrics': {\n",
    "#         'rmse': float(rmse_prophet) if 'rmse_prophet' in globals() else None,\n",
    "#         'mae': float(mae_prophet) if 'mae_prophet' in globals() else None,\n",
    "#         'mape': float(mape_prophet) if 'mape_prophet' in globals() else None,\n",
    "#         'r2': float(r2_prophet) if 'r2_prophet' in globals() else None,\n",
    "#         'directional_accuracy': float(da_prophet) if 'da_prophet' in globals() else None,\n",
    "#     },\n",
    "# }\n",
    "# joblib.dump(prophet_artifact, str(out_dir / 'prophet.joblib'))\n",
    "\n",
    "hybrid_artifact = {\n",
    "    'model_type': 'hybrid',\n",
    "    'prophet': model_prophet,\n",
    "    'xgb': xgb_model,\n",
    "    'feature_columns': feature_cols if 'feature_cols' in globals() else [],\n",
    "    'scaler': scaler if 'scaler' in globals() else None,\n",
    "    'metrics': {\n",
    "        'rmse': float(rmse_hybrid) if 'rmse_hybrid' in globals() else None,\n",
    "        'mae': float(mae_hybrid) if 'mae_hybrid' in globals() else None,\n",
    "        'mape': float(mape_hybrid) if 'mape_hybrid' in globals() else None,\n",
    "        'r2': float(r2_hybrid) if 'r2_hybrid' in globals() else None,\n",
    "        'directional_accuracy': float(da_hybrid) if 'da_hybrid' in globals() else None,\n",
    "    },\n",
    "}\n",
    "joblib.dump(hybrid_artifact, str(out_dir / (emiten + '_hybrid.joblib')))\n",
    "\n",
    "print(\"âœ… Re-saved artifacts with scaler:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3434d",
   "metadata": {},
   "source": [
    "# Export Artifacts with Scaler and Feature Columns\n",
    "This section saves both Prophet and Hybrid (Prophet + XGBoost) artifacts including the fitted `MinMaxScaler` and the list of regressor `feature_columns`. Run these cells after training has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a961e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Prophet/Hybrid artifacts including scaler and feature columns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "# Auto-detect trained objects from this notebook session\n",
    "prophet_model = next((v for v in globals().values() if isinstance(v, Prophet)), None)\n",
    "xgb_model = next((v for v in globals().values() if hasattr(v, 'predict') and v.__class__.__name__.lower().startswith('xgb')), None)\n",
    "scaler = next((v for v in globals().values() if isinstance(v, MinMaxScaler)), None)\n",
    "\n",
    "# Try to infer feature columns from any DataFrame used in training\n",
    "feature_cols = None\n",
    "candidate_dfs = [(name, v) for name, v in globals().items() if isinstance(v, pd.DataFrame)]\n",
    "known_indicators = {'Prev Close','MA20','MA50','MACD','Signal Line','Lag1','Lag2','Lag3','Lag4','Lag5','RSI','BB_upper','BB_lower','ATR','Stochastic_K','Stochastic_D','CCI','OBV','High','Low','Volume'}\n",
    "for name, d in candidate_dfs:\n",
    "    if hasattr(d, 'columns'):\n",
    "        cols = list(d.columns)\n",
    "        if 'ds' in cols and ('y' in cols or 'Close' in cols):\n",
    "            feats = [c for c in cols if c not in ['ds','y','Close']]\n",
    "            if len(set(feats) & known_indicators) >= 5:\n",
    "                feature_cols = feats\n",
    "                break\n",
    "\n",
    "# Fallback: pick columns from the first DataFrame excluding ds/y/Close\n",
    "if feature_cols is None and candidate_dfs:\n",
    "    d = candidate_dfs[0][1]\n",
    "    feature_cols = [c for c in d.columns if c not in ['ds','y','Close']]\n",
    "\n",
    "# Try to pick metrics dicts if present\n",
    "prophet_metrics = next((v for v in globals().values() if isinstance(v, dict) and {'rmse','mae','r2'} <= set(v.keys())), None)\n",
    "hybrid_metrics = next((v for v in globals().values() if isinstance(v, dict) and {'rmse','mae','r2'} <= set(v.keys())), None)\n",
    "\n",
    "print('Found objects:', {\n",
    "    'prophet_model': prophet_model is not None,\n",
    "    'xgb_model': xgb_model is not None,\n",
    "    'scaler': scaler is not None,\n",
    "    'feature_cols': len(feature_cols) if feature_cols else 0,\n",
    "})\n",
    "\n",
    "if scaler is None:\n",
    "    raise RuntimeError('No fitted MinMaxScaler found. Ensure you kept the scaler fitted on training regressors.')\n",
    "if prophet_model is None:\n",
    "    raise RuntimeError('No Prophet model instance found. Please run training before export.')\n",
    "if feature_cols is None or len(feature_cols) == 0:\n",
    "    raise RuntimeError('Could not determine feature_columns from training data.')\n",
    "\n",
    "export_dir = Path('artifacts/models')\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save Prophet\n",
    "# joblib.dump({\n",
    "#     'model_type': 'prophet',\n",
    "#     'prophet': prophet_model,\n",
    "#     'scaler': scaler,\n",
    "#     'feature_columns': feature_cols,\n",
    "#     'metrics': prophet_metrics,\n",
    "# }, export_dir / 'prophet.joblib')\n",
    "\n",
    "# Save Hybrid when XGBoost is available\n",
    "if xgb_model is not None:\n",
    "    joblib.dump({\n",
    "        'model_type': 'hybrid',\n",
    "        'prophet': prophet_model,\n",
    "        'xgb': xgb_model,\n",
    "        'scaler': scaler,\n",
    "        'feature_columns': feature_cols,\n",
    "        'metrics': hybrid_metrics,\n",
    "    }, export_dir / (emiten+'_hybrid.joblib'))\n",
    "    print('Saved hybrid.joblib with scaler and feature_columns')\n",
    "else:\n",
    "    print('No XGBoost model found; saved only prophet.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
